// gateway/routes/index.js
// Registers all route handlers with the Express app.

import helmet from "helmet";
import compression from "compression";
import rateLimit from "express-rate-limit";
import * as prom from "prom-client";
import { randomUUID } from "crypto";

import db from "../db/db.js";
import { completeUseCase } from "../usecases/complete.js";
import { chatUseCase } from "../usecases/chat.js";
import { chatStreamUseCase } from "../usecases/chatStream.js";
import { warmupUseCase } from "../usecases/warmup.js";
import { scanUseCase } from "../usecases/scan.js";
import { queryUseCase } from "../usecases/query.js";
import { loginUseCase, requireAuth } from "../usecases/auth.js";
import { memoryShortUseCase, memoryLongUseCase, memoryList, memoryGet, memoryDelete } from "../usecases/memory.js";
import { getModels } from "../usecases/models.js";

import { runHwOptimizeUseCase, getHwProfileUseCase } from "../usecases/optimize.js";
import { startLlamaServerUseCase, stopLlamaServerUseCase } from "../usecases/runtime.js";
import { trainingGet, trainingPut, trainingPatch, trainingDelete, trainingBuild } from "../usecases/training.js";
import { compressShortToLongUseCase, compressLongGlobalUseCase } from "../usecases/compress.js";

import { validate } from "../middleware/validate.js";
import { ChatSchema, CompleteSchema, ScanSchema, QuerySchema, WarmupSchema, MemoryWriteSchema, TrainingPutSchema, TrainingPatchSchema, TrainingBuildSchema, CompressionSchema } from "../validation/schemas.js";

export default function registerRoutes(app, deps) {
  const { log, getTimeoutMs, OLLAMA, MODEL, MOCK } = deps;

  app.use(helmet());
  app.use(compression());

  prom.collectDefaultMetrics();
  const httpMs = new prom.Histogram({ name: "http_request_duration_ms", help: "HTTP request duration (ms)", labelNames: ["route","method","status"], buckets: [50,100,200,500,1000,2000,5000,10000] });

  app.use((req, res, next) => {
    req.id = randomUUID();
    res.setHeader("X-Request-Id", req.id);
    const t0 = Date.now();
    res.on("finish", () => {
      const routeLabel = req.route && req.route.path ? req.route.path : req.path;
      const dur = Date.now() - t0;
      httpMs.labels(routeLabel, req.method, String(res.statusCode)).observe(dur);
      if (typeof log === "function") log("req", { id:req.id, m:req.method, p:req.path, s:res.statusCode, ms:dur });
    });
    next();
  });

  const chatLimiter = rateLimit({ windowMs: 60_000, max: 30 });
  const memoryLimiter = rateLimit({ windowMs: 60_000, max: 120 });
  const trainingLimiter = rateLimit({ windowMs: 60_000, max: 30 });
  const compressLimiter = rateLimit({ windowMs: 60_000, max: 10 });

  app.get("/health", (_req, res) => res.json({ ok:true, mock:MOCK, model:MODEL, ollama:OLLAMA, timeoutMs:getTimeoutMs(), pid:process.pid }));
  app.get("/ready", async (_req, res) => {
    const base = String(process.env.LLAMACPP_SERVER || "").replace(/\/$/, "");
    if (!base) {
      return res.status(200).json({ ok: true, upstream: "llama.cpp-cli", status: 200 });
    }
    try {
      const r = await fetch(`${base}/v1/models`, { method:'POST', headers:{'content-type':'application/json'}, body:'{}', signal: AbortSignal.timeout(3000) });
      return res.status(r.ok ? 200 : 503).json({ ok: r.ok, upstream: "llama.cpp-server", status: r.status });
    } catch (e) {
      return res.status(503).json({ ok:false, error: (e && e.message) || String(e) });
    }
    });
      return res.status(r.ok ? 200 : 503).json({ ok: r.ok, upstream: "ollama", status: r.status });
    } catch (e) {
      return res.status(503).json({ ok:false, error: String(e && e.message ? e.message : e) });
    }
  });
  app.get("/metrics", async (_req, res) => { res.set("Content-Type", prom.register.contentType); res.end(await prom.register.metrics()); });

  app.post("/complete", validate(CompleteSchema), async (req, res) => { await completeUseCase(req, res, deps); });
  app.post("/chat", chatLimiter, validate(ChatSchema), async (req, res) => { await chatUseCase(req, res, deps); });
  app.post("/chat/stream", chatLimiter, validate(ChatSchema), async (req, res) => { await chatStreamUseCase(req, res, deps); });
  app.get("/models", async (_req, res) => { const models = await getModels(); res.json({ models }); });
  app.post("/warmup", validate(WarmupSchema), async (req, res) => { await warmupUseCase(req, res, deps); });
  app.post("/scan", validate(ScanSchema), async (req, res) => { await scanUseCase(req, res, deps); });
  app.post("/query", validate(QuerySchema), async (req, res) => { await queryUseCase(req, res, deps); });

  app.post("/auth/login", async (req, res) => { await loginUseCase(req, res, deps); });

  // Memory short/long CRUD
  app.get("/memory/short", requireAuth, async (req, res) => { await memoryList(req, res, 'short'); });
  app.get("/memory/short/:memid", requireAuth, async (req, res) => { await memoryGet(req, res, 'short'); });
  app.post("/memory/short", requireAuth, memoryLimiter, validate(MemoryWriteSchema), async (req, res) => { await memoryShortUseCase(req, res, deps); });
  app.delete("/memory/short/:memid", requireAuth, memoryLimiter, async (req, res) => { await memoryDelete(req, res, 'short'); });

  app.get("/memory/long", requireAuth, async (req, res) => { await memoryList(req, res, 'long'); });
  app.get("/memory/long/:memid", requireAuth, async (req, res) => { await memoryGet(req, res, 'long'); });
  app.post("/memory/long", requireAuth, memoryLimiter, validate(MemoryWriteSchema), async (req, res) => { await memoryLongUseCase(req, res, deps); });
  app.delete("/memory/long/:memid", requireAuth, memoryLimiter, async (req, res) => { await memoryDelete(req, res, 'long'); });

  // Training
  app.get("/user/training", requireAuth, trainingLimiter, async (req, res) => { await trainingGet(req, res); });
  app.put("/user/training", requireAuth, trainingLimiter, validate(TrainingPutSchema), async (req, res) => { await trainingPut(req, res); });
  app.patch("/user/training", requireAuth, trainingLimiter, validate(TrainingPatchSchema), async (req, res) => { await trainingPatch(req, res); });
  app.delete("/user/training", requireAuth, trainingLimiter, async (req, res) => { await trainingDelete(req, res); });
  app.post("/user/training/build", requireAuth, trainingLimiter, validate(TrainingBuildSchema), async (req, res) => { await trainingBuild(req, res); });

  // Hardware optimization profile
  app.post("/optimize/hw/run", async (req, res) => { await runHwOptimizeUseCase(req, res, deps); });
  app.get("/optimize/hw", async (req, res) => { await getHwProfileUseCase(req, res); });

  // Runtime control for llama-server
  app.post("/runtime/llama/start", async (req, res) => { await startLlamaServerUseCase(req, res); });
  app.post("/runtime/llama/stop", async (req, res) => { await stopLlamaServerUseCase(req, res); });

  // Compression endpoints
  app.post("/memory/compact/short-to-long", requireAuth, compressLimiter, validate(CompressionSchema), async (req, res) => {
    await (await import("../usecases/compress.js")).compressShortToLongUseCase(req, res, deps);
  });
  app.post("/memory/compact/long", requireAuth, compressLimiter, validate(CompressionSchema), async (req, res) => {
    await (await import("../usecases/compress.js")).compressLongGlobalUseCase(req, res, deps);
  });
}
